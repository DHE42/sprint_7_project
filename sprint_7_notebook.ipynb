{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a58b75a",
   "metadata": {},
   "source": [
    "Project instructions\n",
    "\n",
    "1) Open and look through the data file. Path to the file:datasets/users_behavior.csv Download dataset\n",
    "2) Split the source data into a training set, a validation set, and a test set.\n",
    "3) Investigate the quality of different models by changing hyperparameters. Briefly describe the findings of the study.\n",
    "4) Check the quality of the model using the test set.\n",
    "5) Additional task: sanity check the model. This data is more complex than what you’re used to working with, so it's not an easy task. We'll take a closer look at it later.\n",
    "\n",
    "Here’s what the reviewers will look at when reviewing your project:\n",
    "\n",
    "1) How did you look into data after downloading?\n",
    "2) Have you correctly split the data into train, validation, and test sets?\n",
    "3) How have you chosen the sets' sizes?\n",
    "4) Did you evaluate the quality of the models correctly?\n",
    "5) What models and hyperparameters did you use?\n",
    "6) What are your findings?\n",
    "7) Did you test the models correctly?\n",
    "8) What is your accuracy score?\n",
    "9) Have you stuck to the project structure and kept the code neat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a4a09d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n",
      "\n",
      "             calls      minutes     messages       mb_used     is_ultra\n",
      "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
      "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
      "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
      "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
      "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
      "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
      "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
      "max     244.000000  1632.060000   224.000000  49745.730000     1.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/DHE42/sprint_7_project/refs/heads/main/users_behavior.csv'\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "print(df.head())\n",
    "print()\n",
    "\n",
    "print(df.info())\n",
    "print()\n",
    "\n",
    "print(df.describe())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eb86be55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare features and target\n",
    "features = df.drop(['is_ultra'], axis=1)\n",
    "target = df['is_ultra']\n",
    "\n",
    "\n",
    "# Split of a 20% test set\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=12345\n",
    ")\n",
    "\n",
    "# Split features_train and target_train into training (60%) and validation (20%)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features_train, target_train, test_size=0.25, random_state=12345\n",
    ")\n",
    "\n",
    "def evaluate_model(model, features_valid, target_valid, features_test, target_test, model_name=\"Model\"):\n",
    "   \n",
    "    # Validation set predictions and accuracy\n",
    "    valid_predictions = model.predict(features_valid)\n",
    "    valid_accuracy = accuracy_score(target_valid, valid_predictions)\n",
    "    print(f\"{model_name} Validation Accuracy: {valid_accuracy}\")\n",
    "    \n",
    "    # Test set predictions and accuracy\n",
    "    test_predictions = model.predict(features_test)\n",
    "    test_accuracy = accuracy_score(target_test, test_predictions)\n",
    "    print(f\"{model_name} Test Accuracy: {test_accuracy}\")\n",
    "    \n",
    "    # Error count\n",
    "    validation_errors = sum(target_valid != valid_predictions)\n",
    "    test_errors = sum(target_test != test_predictions)\n",
    "    print(f\"{model_name} Validation Errors: {validation_errors}\")\n",
    "    print(f\"{model_name} Test Errors: {test_errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c1ff63",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbace234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Validation Accuracy: 0.7589424572317263\n",
      "Decision Tree Test Accuracy: 0.7884914463452566\n",
      "Decision Tree Validation Errors: 155\n",
      "Decision Tree Test Errors: 136\n"
     ]
    }
   ],
   "source": [
    "tree_model = DecisionTreeClassifier(random_state=12345, max_depth=5)\n",
    "tree_model.fit(features_train, target_train)\n",
    "\n",
    "def explore_decision_tree_hyperparameters(features_train, target_train, features_valid, target_valid, features_test, target_test):\n",
    "    # List of hyperparameter configurations to try\n",
    "    configs = [\n",
    "        # Depth variations\n",
    "        {'max_depth': 3, 'min_samples_split': 2, 'criterion': 'gini'},\n",
    "        {'max_depth': 5, 'min_samples_split': 2, 'criterion': 'gini'},\n",
    "        {'max_depth': 7, 'min_samples_split': 2, 'criterion': 'gini'},\n",
    "        {'max_depth': None, 'min_samples_split': 2, 'criterion': 'gini'},\n",
    "        \n",
    "        # Splitting variations\n",
    "        {'max_depth': 5, 'min_samples_split': 5, 'criterion': 'gini'},\n",
    "        {'max_depth': 5, 'min_samples_split': 10, 'criterion': 'gini'},\n",
    "        \n",
    "        # Criterion variations\n",
    "        {'max_depth': 5, 'min_samples_split': 2, 'criterion': 'entropy'},\n",
    "        \n",
    "        # Leaf node variations\n",
    "        {'max_depth': 5, 'min_samples_leaf': 2, 'criterion': 'gini'},\n",
    "        {'max_depth': 5, 'min_samples_leaf': 4, 'criterion': 'gini'}\n",
    "    ]\n",
    "    \n",
    "    # Store results\n",
    "    results = []\n",
    "    \n",
    "    # Iterate through configurations\n",
    "    for config in configs:\n",
    "        print(\"\\nConfiguration:\", config)\n",
    "        \n",
    "        # Create and train the model\n",
    "        tree_model = DecisionTreeClassifier(\n",
    "            random_state=12345,\n",
    "            **config  # Unpack the configuration\n",
    "        )\n",
    "        tree_model.fit(features_train, target_train)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        valid_predictions = tree_model.predict(features_valid)\n",
    "        test_predictions = tree_model.predict(features_test)\n",
    "        \n",
    "        valid_accuracy = accuracy_score(target_valid, valid_predictions)\n",
    "        test_accuracy = accuracy_score(target_test, test_predictions)\n",
    "        \n",
    "        # Store results\n",
    "        result = config.copy()\n",
    "        result['valid_accuracy'] = valid_accuracy\n",
    "        result['test_accuracy'] = test_accuracy\n",
    "        results.append(result)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"Validation Accuracy: {valid_accuracy:.4f}\")\n",
    "        print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Sort results by test accuracy\n",
    "    results_sorted = sorted(results, key=lambda x: x['test_accuracy'], reverse=True)\n",
    "    \n",
    "    print(\"\\nTop Performing Configurations:\")\n",
    "    for result in results_sorted[:3]:\n",
    "        print(result)\n",
    "    \n",
    "    return results_sorted\n",
    "\n",
    "# Use the function\n",
    "hyperparameter_results = explore_decision_tree_hyperparameters(\n",
    "    features_train, target_\n",
    "\n",
    "\n",
    "evaluate_model(tree_model, features_valid, target_valid, features_test, target_test, model_name=\"Decision Tree\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d402c67",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d1c5e52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Validation Accuracy: 0.7962674961119751\n",
      "Random Forest Test Accuracy: 0.8009331259720062\n",
      "Random Forest Validation Errors: 131\n",
      "Random Forest Test Errors: 128\n"
     ]
    }
   ],
   "source": [
    "forest_model = RandomForestClassifier(random_state=12345, n_estimators=100, max_depth=10)\n",
    "forest_model.fit(features_train, target_train)\n",
    "\n",
    "evaluate_model(forest_model, features_valid, target_valid, features_test, target_test, model_name=\"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fc8562",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "98573f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Validation Accuracy: 0.7262830482115086\n",
      "Logistic Regression Test Accuracy: 0.7589424572317263\n",
      "Logistic Regression Validation Errors: 176\n",
      "Logistic Regression Test Errors: 155\n"
     ]
    }
   ],
   "source": [
    "regression_model = LogisticRegression(random_state=12345, max_iter=1000)\n",
    "regression_model.fit(features_train, target_train)\n",
    "\n",
    "\n",
    "evaluate_model(regression_model, features_valid, target_valid, features_test, target_test, model_name=\"Logistic Regression\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
